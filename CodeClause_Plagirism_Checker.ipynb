{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8evzd9FmYJ45",
        "outputId": "d4353f78-4d70-4440-81dd-0e7eb644d04f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('2.txt', '3.txt', 0.14806887549598566)\n",
            "('1.txt', '3.txt', 0.1864344837032336)\n",
            "('1.txt', '2.txt', 0.5465972177348937)\n",
            "\n",
            "Highest Plagiarism is: 54.659721773489366% Between 1.txt & 2.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from numpy import vectorize \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        " \n",
        "files = [doc for doc in os.listdir() if doc.endswith('.txt')]\n",
        "contents = [open(File).read() for File in files]\n",
        " \n",
        "vectorize = lambda Text: TfidfVectorizer().fit_transform(Text).toarray()\n",
        "similarity = lambda doc1, doc2: cosine_similarity([doc1, doc2])\n",
        " \n",
        "vectors = vectorize(contents)\n",
        "s_vectors = list(zip(files, vectors))\n",
        " \n",
        "def check_plagiarism():\n",
        "    results = set()\n",
        "    global s_vectors\n",
        "    for sample_a, text_vector_a in s_vectors:\n",
        "        new_vectors = s_vectors.copy()\n",
        "        current_index = new_vectors.index((sample_a, text_vector_a))\n",
        "        del new_vectors[current_index]\n",
        "        for sample_b, text_vector_b in new_vectors:\n",
        "            sim_score = similarity(text_vector_a, text_vector_b)[0][1]\n",
        "            sample_pair = sorted((sample_a, sample_b))\n",
        "            score = sample_pair[0], sample_pair[1], sim_score\n",
        "            results.add(score)\n",
        "    return results\n",
        "\n",
        "# Analyzing results\n",
        "highest = 0\n",
        "index1 = ''\n",
        "index2 = '' \n",
        "\n",
        "for data in check_plagiarism():\n",
        "    print(data)  \n",
        "    \n",
        "    if data[2] > highest:\n",
        "      highest = data[2]\n",
        "\n",
        "      index1 = data[0]\n",
        "      index2 = data[1]\n",
        "print()\n",
        "print(\"Highest Plagiarism is: \" + str(highest*100) + \"% Between \" + index1 + \" & \" + index2)      "
      ]
    }
  ]
}